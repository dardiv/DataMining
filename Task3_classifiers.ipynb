{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers evaluation and comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets, dummy, metrics, tree, svm, linear_model, ensemble, naive_bayes\n",
    "from sklearn import model_selection as ms\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_baseline(data, target):\n",
    "    baseline = dummy.DummyClassifier(strategy='most_frequent')\n",
    "    baseline.fit(data, target)\n",
    "    base_predictions = baseline.predict(data)\n",
    "    base_accuracy = metrics.accuracy_score(target, base_predictions)\n",
    "\n",
    "    print (\"Baseline accuracy = {:.3f}\".format(base_accuracy))\n",
    "    print(metrics.classification_report(target, base_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cross(model, test_data, test_labels):\n",
    "    predictions = ms.cross_val_predict(model, test_data, test_labels)\n",
    "\n",
    "    f1 = metrics.f1_score(test_labels, predictions, average='weighted')\n",
    "    print('Cross-validation predictions:')\n",
    "    print (\"F1 = {:.3f}\".format(f1))\n",
    "\n",
    "    print(metrics.classification_report(test_labels, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_classifier(classifier, params, train_data, test_data, train_labels, folds, f1_scorer): \n",
    "    grid = ms.GridSearchCV(classifier,\n",
    "                           params,\n",
    "                           refit=True,\n",
    "                           scoring=f1_scorer,\n",
    "                           iid = True,\n",
    "                           cv=ms.StratifiedKFold(n_splits=folds))\n",
    "    \n",
    "    grid_best = grid.fit(train_data, train_labels)\n",
    "    print(\"Best hyper-parameters: {}\".format(grid_best.best_params_))\n",
    "    predictions = grid_best.predict(test_data)\n",
    "    f1 = metrics.f1_score(test_labels, predictions, average='weighted')\n",
    "    print (\"F1 = {:.3f}\".format(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distibution\n",
      "3    183\n",
      "5    182\n",
      "1    182\n",
      "6    181\n",
      "4    181\n",
      "9    180\n",
      "7    179\n",
      "0    178\n",
      "2    177\n",
      "8    174\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "digits = datasets.load_digits()\n",
    "\n",
    "digits_frame = pd.DataFrame(digits.data)\n",
    "digits_frame['target'] = digits.target\n",
    "\n",
    "print (\"Class distibution\")\n",
    "print (digits_frame['target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_d = digits_frame['target'] \n",
    "data_d = digits_frame.drop(columns = ['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distibution\n",
      "1    357\n",
      "0    212\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "breast_cancer = datasets.load_breast_cancer()\n",
    "\n",
    "breast_cancer_frame = pd.DataFrame(breast_cancer.data)\n",
    "breast_cancer_frame['target'] = breast_cancer.target\n",
    "\n",
    "print (\"Class distibution\")\n",
    "print (breast_cancer_frame['target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_b = breast_cancer_frame['target']\n",
    "data_b = breast_cancer_frame.drop(columns = ['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distibution\n",
      "1    71\n",
      "0    59\n",
      "2    48\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "wine = datasets.load_wine()\n",
    "\n",
    "wine_frame = pd.DataFrame(wine.data)\n",
    "wine_frame['target'] = wine.target\n",
    "\n",
    "print (\"Class distibution\")\n",
    "print (wine_frame['target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_w = wine_frame['target']\n",
    "data_w = wine_frame.drop(columns = ['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digit dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy = 0.102\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       178\n",
      "           1       0.00      0.00      0.00       182\n",
      "           2       0.00      0.00      0.00       177\n",
      "           3       0.10      1.00      0.18       183\n",
      "           4       0.00      0.00      0.00       181\n",
      "           5       0.00      0.00      0.00       182\n",
      "           6       0.00      0.00      0.00       181\n",
      "           7       0.00      0.00      0.00       179\n",
      "           8       0.00      0.00      0.00       174\n",
      "           9       0.00      0.00      0.00       180\n",
      "\n",
      "    accuracy                           0.10      1797\n",
      "   macro avg       0.01      0.10      0.02      1797\n",
      "weighted avg       0.01      0.10      0.02      1797\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_baseline(data_d, target_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find best classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_labels = ms.train_test_split(data_d, target_d, test_size = 0.3, random_state=42)\n",
    "folds = 5\n",
    "f1_scorer  = metrics.make_scorer(metrics.f1_score, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: {'C': 1, 'max_iter': 100, 'penalty': 'l1', 'tol': 0.0001}\n",
      "F1 = 0.963\n",
      "Cross-validation predictions:\n",
      "F1 = 0.959\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       0.94      0.96      0.95        50\n",
      "           2       1.00      0.98      0.99        47\n",
      "           3       0.96      0.96      0.96        54\n",
      "           4       0.95      0.98      0.97        60\n",
      "           5       0.95      0.95      0.95        66\n",
      "           6       0.96      0.98      0.97        53\n",
      "           7       0.98      0.95      0.96        55\n",
      "           8       0.95      0.91      0.93        43\n",
      "           9       0.90      0.92      0.91        59\n",
      "\n",
      "    accuracy                           0.96       540\n",
      "   macro avg       0.96      0.96      0.96       540\n",
      "weighted avg       0.96      0.96      0.96       540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logistic_param = {'penalty': ['l1', 'l2'],\n",
    "                  'C': [1, 10, 100],\n",
    "                  'max_iter': [100, 300],\n",
    "                  'tol': [1e-3, 1e-4]}\n",
    "\n",
    "logistic_classifier = linear_model.LogisticRegression(random_state=1, solver='liblinear')\n",
    "load_classifier(logistic_classifier, logistic_param,\n",
    "                train_data, test_data, train_labels,\n",
    "                folds, f1_scorer)\n",
    "\n",
    "get_cross(logistic_classifier, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "F1 = 0.989\n",
      "Cross-validation predictions:\n",
      "F1 = 0.972\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       0.93      1.00      0.96        50\n",
      "           2       1.00      0.96      0.98        47\n",
      "           3       1.00      0.96      0.98        54\n",
      "           4       0.98      1.00      0.99        60\n",
      "           5       0.97      0.97      0.97        66\n",
      "           6       0.98      1.00      0.99        53\n",
      "           7       0.98      0.98      0.98        55\n",
      "           8       0.90      0.88      0.89        43\n",
      "           9       0.97      0.95      0.96        59\n",
      "\n",
      "    accuracy                           0.97       540\n",
      "   macro avg       0.97      0.97      0.97       540\n",
      "weighted avg       0.97      0.97      0.97       540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc_param = {'kernel': ['linear','poly','rbf'],\n",
    "            'gamma': ['auto', 'scale'],\n",
    "            'C': [1, 10, 100]}\n",
    "\n",
    "svc_classifier = svm.SVC(probability=True)\n",
    "load_classifier(svc_classifier, svc_param,\n",
    "                train_data, test_data, train_labels,\n",
    "                folds, f1_scorer)\n",
    "\n",
    "get_cross(svc_classifier, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: {'max_depth': 10, 'max_features': None, 'min_samples_leaf': 1, 'presort': True}\n",
      "F1 = 0.847\n",
      "Cross-validation predictions:\n",
      "F1 = 0.806\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.89      0.94        53\n",
      "           1       0.70      0.70      0.70        50\n",
      "           2       0.85      0.70      0.77        47\n",
      "           3       0.84      0.87      0.85        54\n",
      "           4       0.87      0.75      0.80        60\n",
      "           5       0.79      0.85      0.82        66\n",
      "           6       0.85      0.94      0.89        53\n",
      "           7       0.77      0.84      0.80        55\n",
      "           8       0.72      0.79      0.76        43\n",
      "           9       0.71      0.71      0.71        59\n",
      "\n",
      "    accuracy                           0.81       540\n",
      "   macro avg       0.81      0.80      0.80       540\n",
      "weighted avg       0.81      0.81      0.81       540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_param = {'presort':[True, False],\n",
    "                  'max_depth' : [ 2, 3, 5, 7, 10],\n",
    "                  'max_features' : ['auto', 1, 2, 3, None],\n",
    "                  'min_samples_leaf' : [1, 2, 3, 4, 5]}\n",
    "\n",
    "decision_classifier = tree.DecisionTreeClassifier(random_state=1)\n",
    "load_classifier(decision_classifier, decision_param,\n",
    "                train_data, test_data, train_labels,\n",
    "                folds, f1_scorer)\n",
    "\n",
    "get_cross(decision_classifier, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: {'var_smoothing': 0.001}\n",
      "F1 = 0.896\n",
      "Cross-validation predictions:\n",
      "F1 = 0.871\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.87      0.93        53\n",
      "           1       0.85      0.80      0.82        50\n",
      "           2       0.87      0.85      0.86        47\n",
      "           3       0.87      0.85      0.86        54\n",
      "           4       0.90      0.92      0.91        60\n",
      "           5       0.91      0.94      0.93        66\n",
      "           6       0.96      0.92      0.94        53\n",
      "           7       0.78      0.98      0.87        55\n",
      "           8       0.69      0.86      0.76        43\n",
      "           9       0.91      0.69      0.79        59\n",
      "\n",
      "    accuracy                           0.87       540\n",
      "   macro avg       0.87      0.87      0.87       540\n",
      "weighted avg       0.88      0.87      0.87       540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "naive_param = {'var_smoothing' : [ 1e-3, 1e-5, 1e-7, 1e-9]}\n",
    "\n",
    "naive_classifier = naive_bayes.GaussianNB()\n",
    "load_classifier(naive_classifier, naive_param,\n",
    "                train_data, test_data, train_labels,\n",
    "                folds, f1_scorer)\n",
    "\n",
    "get_cross(naive_classifier, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: {'max_depth': None, 'max_features': 'log2', 'n_estimators': 250}\n",
      "F1 = 0.970\n",
      "Cross-validation predictions:\n",
      "F1 = 0.968\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       0.94      1.00      0.97        50\n",
      "           2       1.00      0.94      0.97        47\n",
      "           3       0.96      0.96      0.96        54\n",
      "           4       0.97      1.00      0.98        60\n",
      "           5       0.97      0.97      0.97        66\n",
      "           6       0.98      0.98      0.98        53\n",
      "           7       0.96      0.98      0.97        55\n",
      "           8       0.93      0.93      0.93        43\n",
      "           9       0.96      0.92      0.94        59\n",
      "\n",
      "    accuracy                           0.97       540\n",
      "   macro avg       0.97      0.97      0.97       540\n",
      "weighted avg       0.97      0.97      0.97       540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "forest_param = {'max_depth' : [None, 5, 10, 25],\n",
    "                'max_features' : ['auto', 'log2', None],\n",
    "                'n_estimators' : [50, 100, 250]}\n",
    "\n",
    "forest_classifier = ensemble.RandomForestClassifier(random_state=1)\n",
    "load_classifier(forest_classifier, forest_param,\n",
    "                train_data, test_data, train_labels,\n",
    "                folds, f1_scorer)\n",
    "\n",
    "get_cross(forest_classifier, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: {'algorithm': 'SAMME', 'learning_rate': 1, 'n_estimators': 100}\n",
      "F1 = 0.798\n",
      "Cross-validation predictions:\n",
      "F1 = 0.200\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.74      0.63        53\n",
      "           1       0.00      0.00      0.00        50\n",
      "           2       0.00      0.00      0.00        47\n",
      "           3       0.00      0.00      0.00        54\n",
      "           4       0.18      0.22      0.20        60\n",
      "           5       0.40      0.41      0.41        66\n",
      "           6       0.67      0.04      0.07        53\n",
      "           7       0.19      0.38      0.25        55\n",
      "           8       0.00      0.00      0.00        43\n",
      "           9       0.20      0.73      0.31        59\n",
      "\n",
      "    accuracy                           0.27       540\n",
      "   macro avg       0.22      0.25      0.19       540\n",
      "weighted avg       0.23      0.27      0.20       540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "boost_param = {'n_estimators' : [20, 50, 100],\n",
    "               'learning_rate' : [1, 1e-2],\n",
    "               'algorithm': ['SAMME', 'SAMME.R']}\n",
    "\n",
    "boost_classifier = ensemble.AdaBoostClassifier()\n",
    "load_classifier(boost_classifier, boost_param,                \n",
    "                train_data, test_data, train_labels,\n",
    "                folds, f1_scorer)\n",
    "\n",
    "get_cross(boost_classifier, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: {'flatten_transform': True, 'voting': 'hard'}\n",
      "F1 = 0.961\n",
      "Cross-validation predictions:\n",
      "F1 = 0.966\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       0.92      0.98      0.95        50\n",
      "           2       1.00      0.96      0.98        47\n",
      "           3       0.96      0.94      0.95        54\n",
      "           4       0.97      1.00      0.98        60\n",
      "           5       0.97      0.98      0.98        66\n",
      "           6       0.98      0.98      0.98        53\n",
      "           7       0.95      1.00      0.97        55\n",
      "           8       0.93      0.93      0.93        43\n",
      "           9       0.98      0.88      0.93        59\n",
      "\n",
      "    accuracy                           0.97       540\n",
      "   macro avg       0.97      0.97      0.97       540\n",
      "weighted avg       0.97      0.97      0.97       540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "voting_param = {'voting' : ['hard', 'soft'],\n",
    "                'flatten_transform' :[True, False, None]}\n",
    "\n",
    "voting_classifier = ensemble.VotingClassifier(estimators=[('lr', logistic_classifier), \n",
    "                                            ('rf', ensemble.RandomForestClassifier(n_estimators=50, random_state=1)), \n",
    "                                            ('gnb', naive_classifier)])\n",
    "load_classifier(voting_classifier, voting_param,\n",
    "                train_data, test_data, train_labels,\n",
    "                folds, f1_scorer)\n",
    "\n",
    "get_cross(voting_classifier, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breast_can—Åer dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy = 0.627\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       212\n",
      "           1       0.63      1.00      0.77       357\n",
      "\n",
      "    accuracy                           0.63       569\n",
      "   macro avg       0.31      0.50      0.39       569\n",
      "weighted avg       0.39      0.63      0.48       569\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_baseline(data_b, target_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find best classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_labels = ms.train_test_split(data_b, target_b, test_size = 0.3, random_state=42)\n",
    "folds = 5\n",
    "f1_scorer  = metrics.make_scorer(metrics.f1_score, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: {'C': 100, 'max_iter': 200, 'penalty': 'l1', 'tol': 0.001}\n",
      "F1 = 0.977\n",
      "Cross-validation predictions:\n",
      "F1 = 0.953\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.94        63\n",
      "           1       0.95      0.97      0.96       108\n",
      "\n",
      "    accuracy                           0.95       171\n",
      "   macro avg       0.95      0.95      0.95       171\n",
      "weighted avg       0.95      0.95      0.95       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logistic_param = {'penalty': ['l1', 'l2'],\n",
    "                   'C': [1, 10, 100],\n",
    "                   'max_iter': [200, 500],\n",
    "                   'tol': [1e-3, 1e-4]}\n",
    "\n",
    "load_classifier(logistic_classifier, logistic_param,\n",
    "                train_data, test_data, train_labels,\n",
    "                folds, f1_scorer)\n",
    "\n",
    "get_cross(logistic_classifier, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: {'C': 10, 'gamma': 'auto', 'kernel': 'linear'}\n",
      "F1 = 0.971\n",
      "Cross-validation predictions:\n",
      "F1 = 0.928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.83      0.90        63\n",
      "           1       0.91      0.99      0.95       108\n",
      "\n",
      "    accuracy                           0.93       171\n",
      "   macro avg       0.94      0.91      0.92       171\n",
      "weighted avg       0.93      0.93      0.93       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc_param = {'kernel': ['linear','rbf'],\n",
    "            'gamma': ['auto', 'scale'],\n",
    "            'C': [1, 10]}\n",
    "\n",
    "svc_classifier = svm.SVC()\n",
    "load_classifier(svc_classifier, svc_param,\n",
    "                train_data, test_data, train_labels,\n",
    "                folds, f1_scorer)\n",
    "\n",
    "get_cross(svc_classifier, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: {'max_depth': 7, 'max_features': 1, 'min_samples_leaf': 2, 'presort': True}\n",
      "F1 = 0.953\n",
      "Cross-validation predictions:\n",
      "F1 = 0.930\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90        63\n",
      "           1       0.94      0.94      0.94       108\n",
      "\n",
      "    accuracy                           0.93       171\n",
      "   macro avg       0.92      0.92      0.92       171\n",
      "weighted avg       0.93      0.93      0.93       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_param = {'presort':[True, False],\n",
    "                  'max_depth' : [ 2, 3, 5, 7, 10],\n",
    "                  'max_features' : ['auto', 1, 2, 3, None],\n",
    "                  'min_samples_leaf' : [1, 2, 3, 4, 5]}\n",
    "\n",
    "decision_classifier = tree.DecisionTreeClassifier(random_state=1)\n",
    "load_classifier(decision_classifier, decision_param,\n",
    "                train_data, test_data, train_labels,\n",
    "                folds, f1_scorer)\n",
    "\n",
    "get_cross(decision_classifier, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: {'var_smoothing': 1e-09}\n",
      "F1 = 0.941\n",
      "Cross-validation predictions:\n",
      "F1 = 0.941\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.89      0.92        63\n",
      "           1       0.94      0.97      0.95       108\n",
      "\n",
      "    accuracy                           0.94       171\n",
      "   macro avg       0.94      0.93      0.94       171\n",
      "weighted avg       0.94      0.94      0.94       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "naive_param = {'var_smoothing' : [ 1e-3, 1e-5, 1e-7, 1e-9]}\n",
    "\n",
    "naive_classifier = naive_bayes.GaussianNB()\n",
    "load_classifier(naive_classifier, naive_param,\n",
    "                train_data, test_data, train_labels,\n",
    "                folds, f1_scorer)\n",
    "\n",
    "get_cross(naive_classifier, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: {'max_depth': None, 'max_features': None, 'n_estimators': 50}\n",
      "F1 = 0.959\n",
      "Cross-validation predictions:\n",
      "F1 = 0.947\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93        63\n",
      "           1       0.95      0.96      0.96       108\n",
      "\n",
      "    accuracy                           0.95       171\n",
      "   macro avg       0.94      0.94      0.94       171\n",
      "weighted avg       0.95      0.95      0.95       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "forest_param = {'max_depth' : [None, 5, 10, 25],\n",
    "                'max_features' : ['auto', 'log2', None],\n",
    "                'n_estimators' : [50, 100, 250]}\n",
    "\n",
    "forest_classifier = ensemble.RandomForestClassifier(random_state=1)\n",
    "load_classifier(forest_classifier, forest_param,\n",
    "                train_data, test_data, train_labels,\n",
    "                folds, f1_scorer)\n",
    "\n",
    "get_cross(forest_classifier, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: {'algorithm': 'SAMME', 'learning_rate': 1, 'n_estimators': 50}\n",
      "F1 = 0.971\n",
      "Cross-validation predictions:\n",
      "F1 = 0.953\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        63\n",
      "           1       0.96      0.96      0.96       108\n",
      "\n",
      "    accuracy                           0.95       171\n",
      "   macro avg       0.95      0.95      0.95       171\n",
      "weighted avg       0.95      0.95      0.95       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "boost_param = {'n_estimators' : [20, 50, 100],\n",
    "               'learning_rate' : [1, 1e-2],\n",
    "               'algorithm': ['SAMME', 'SAMME.R']}\n",
    "\n",
    "boost_classifier = ensemble.AdaBoostClassifier()\n",
    "load_classifier(boost_classifier, boost_param,                \n",
    "                train_data, test_data, train_labels,\n",
    "                folds, f1_scorer)\n",
    "\n",
    "get_cross(boost_classifier, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: {'flatten_transform': True, 'voting': 'hard'}\n",
      "F1 = 0.971\n",
      "Cross-validation predictions:\n",
      "F1 = 0.959\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.94        63\n",
      "           1       0.95      0.98      0.97       108\n",
      "\n",
      "    accuracy                           0.96       171\n",
      "   macro avg       0.96      0.95      0.96       171\n",
      "weighted avg       0.96      0.96      0.96       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "voting_param = {'voting' : ['hard', 'soft'],\n",
    "                'flatten_transform' :[True, False, None]}\n",
    "\n",
    "voting_classifier = ensemble.VotingClassifier(estimators=[('lr', logistic_classifier), \n",
    "                                            ('rf', ensemble.RandomForestClassifier(n_estimators=50, random_state=1)), \n",
    "                                            ('gnb', naive_classifier)])\n",
    "load_classifier(voting_classifier, voting_param,\n",
    "                train_data, test_data, train_labels,\n",
    "                folds, f1_scorer)\n",
    "\n",
    "get_cross(voting_classifier, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wine dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy = 0.399\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        59\n",
      "           1       0.40      1.00      0.57        71\n",
      "           2       0.00      0.00      0.00        48\n",
      "\n",
      "    accuracy                           0.40       178\n",
      "   macro avg       0.13      0.33      0.19       178\n",
      "weighted avg       0.16      0.40      0.23       178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_baseline(data_w, target_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find best classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_labels = ms.train_test_split(data_w, target_w, test_size = 0.3, random_state=42)\n",
    "folds = 5\n",
    "f1_scorer  = metrics.make_scorer(metrics.f1_score, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: {'C': 100, 'max_iter': 200, 'penalty': 'l1', 'tol': 0.001}\n",
      "F1 = 1.000\n",
      "Cross-validation predictions:\n",
      "F1 = 0.944\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.92        19\n",
      "           1       0.91      1.00      0.95        21\n",
      "           2       1.00      0.93      0.96        14\n",
      "\n",
      "    accuracy                           0.94        54\n",
      "   macro avg       0.95      0.94      0.95        54\n",
      "weighted avg       0.95      0.94      0.94        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logistic_param = {'penalty': ['l1', 'l2'],\n",
    "                   'C': [1, 10, 100],\n",
    "                   'max_iter': [200, 500],\n",
    "                   'tol': [1e-3, 1e-4]}\n",
    "\n",
    "load_classifier(logistic_classifier, logistic_param,\n",
    "                train_data, test_data, train_labels,\n",
    "                folds, f1_scorer)\n",
    "\n",
    "get_cross(logistic_classifier, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: {'C': 1, 'gamma': 'auto', 'kernel': 'linear'}\n",
      "F1 = 0.982\n",
      "Cross-validation predictions:\n",
      "F1 = 0.625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95        19\n",
      "           1       0.60      1.00      0.75        21\n",
      "           2       0.00      0.00      0.00        14\n",
      "\n",
      "    accuracy                           0.72        54\n",
      "   macro avg       0.52      0.65      0.57        54\n",
      "weighted avg       0.57      0.72      0.62        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc_param = {'kernel': ['linear','rbf'],\n",
    "            'gamma': ['auto', 'scale'],\n",
    "            'C': [1, 10]}\n",
    "\n",
    "svc_classifier = svm.SVC()\n",
    "load_classifier(svc_classifier, svc_param,\n",
    "                train_data, test_data, train_labels,\n",
    "                folds, f1_scorer)\n",
    "\n",
    "get_cross(svc_classifier, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: {'max_depth': 3, 'max_features': None, 'min_samples_leaf': 2, 'presort': True}\n",
      "F1 = 0.963\n",
      "Cross-validation predictions:\n",
      "F1 = 0.925\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97        19\n",
      "           1       0.95      0.90      0.93        21\n",
      "           2       0.86      0.86      0.86        14\n",
      "\n",
      "    accuracy                           0.93        54\n",
      "   macro avg       0.92      0.92      0.92        54\n",
      "weighted avg       0.93      0.93      0.93        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_param = {'presort':[True, False],\n",
    "                  'max_depth' : [ 2, 3, 5, 7, 10],\n",
    "                  'max_features' : ['auto', 1, 2, 3, None],\n",
    "                  'min_samples_leaf' : [1, 2, 3, 4, 5]}\n",
    "\n",
    "decision_classifier = tree.DecisionTreeClassifier(random_state=1)\n",
    "load_classifier(decision_classifier, decision_param,\n",
    "                train_data, test_data, train_labels,\n",
    "                folds, f1_scorer)\n",
    "\n",
    "get_cross(decision_classifier, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: {'var_smoothing': 1e-09}\n",
      "F1 = 1.000\n",
      "Cross-validation predictions:\n",
      "F1 = 1.000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      1.00      1.00        21\n",
      "           2       1.00      1.00      1.00        14\n",
      "\n",
      "    accuracy                           1.00        54\n",
      "   macro avg       1.00      1.00      1.00        54\n",
      "weighted avg       1.00      1.00      1.00        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "naive_param = {'var_smoothing' : [ 1e-3, 1e-5, 1e-7, 1e-9]}\n",
    "\n",
    "naive_classifier = naive_bayes.GaussianNB()\n",
    "load_classifier(naive_classifier, naive_param,\n",
    "                train_data, test_data, train_labels,\n",
    "                folds, f1_scorer)\n",
    "\n",
    "get_cross(naive_classifier, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: {'max_depth': None, 'max_features': 'auto', 'n_estimators': 100}\n",
      "F1 = 0.982\n",
      "Cross-validation predictions:\n",
      "F1 = 0.982\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      0.95      0.98        21\n",
      "           2       0.93      1.00      0.97        14\n",
      "\n",
      "    accuracy                           0.98        54\n",
      "   macro avg       0.98      0.98      0.98        54\n",
      "weighted avg       0.98      0.98      0.98        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "forest_param = {'max_depth' : [None, 5, 10, 25],\n",
    "                'max_features' : ['auto', 'log2', None],\n",
    "                'n_estimators' : [50, 100, 250]}\n",
    "\n",
    "forest_classifier = ensemble.RandomForestClassifier(random_state=1)\n",
    "load_classifier(forest_classifier, forest_param,\n",
    "                train_data, test_data, train_labels,\n",
    "                folds, f1_scorer)\n",
    "\n",
    "get_cross(forest_classifier, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: {'algorithm': 'SAMME', 'learning_rate': 1, 'n_estimators': 20}\n",
      "F1 = 0.944\n",
      "Cross-validation predictions:\n",
      "F1 = 0.944\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97        19\n",
      "           1       0.95      0.95      0.95        21\n",
      "           2       0.92      0.86      0.89        14\n",
      "\n",
      "    accuracy                           0.94        54\n",
      "   macro avg       0.94      0.94      0.94        54\n",
      "weighted avg       0.94      0.94      0.94        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "boost_param = {'n_estimators' : [20, 50, 100],\n",
    "               'learning_rate' : [1, 1e-2],\n",
    "               'algorithm': ['SAMME', 'SAMME.R']}\n",
    "\n",
    "boost_classifier = ensemble.AdaBoostClassifier()\n",
    "load_classifier(boost_classifier, boost_param,                \n",
    "                train_data, test_data, train_labels,\n",
    "                folds, f1_scorer)\n",
    "\n",
    "get_cross(boost_classifier, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: {'flatten_transform': True, 'voting': 'hard'}\n",
      "F1 = 1.000\n",
      "Cross-validation predictions:\n",
      "F1 = 1.000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      1.00      1.00        21\n",
      "           2       1.00      1.00      1.00        14\n",
      "\n",
      "    accuracy                           1.00        54\n",
      "   macro avg       1.00      1.00      1.00        54\n",
      "weighted avg       1.00      1.00      1.00        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "voting_param = {'voting' : ['hard', 'soft'],\n",
    "                'flatten_transform' :[True, False, None]}\n",
    "\n",
    "voting_classifier = ensemble.VotingClassifier(estimators=[('lr', logistic_classifier), \n",
    "                                            ('rf', ensemble.RandomForestClassifier(n_estimators=50, random_state=1)), \n",
    "                                            ('gnb', naive_classifier)])\n",
    "load_classifier(voting_classifier, voting_param,\n",
    "                train_data, test_data, train_labels,\n",
    "                folds, f1_scorer)\n",
    "\n",
    "get_cross(voting_classifier, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Digits\n",
    "\n",
    "<table>\n",
    "    <tr><td>Classifier</td><td>F1</td></tr>\n",
    "    <tr><td>LogisticRegression</td><td>0.963</td></tr>\n",
    "    <tr><td>SVM</td><td>0.989</td></tr>\n",
    "    <tr><td>DecisionTreeClassifier</td><td>0.847</td></tr>\n",
    "    <tr><td>NaiveBayes</td><td>0.896</td></tr>\n",
    "    <tr><td>RandomForestClassifier</td><td>0.970</td></tr>\n",
    "    <tr><td>AdaBoostClassifier</td><td>0.798</td></tr>\n",
    "    <tr><td>VotingClassifier</td><td>0.961</td></tr>\n",
    "</table>\n",
    "\n",
    "### Breast_cancer\n",
    "\n",
    "<table>\n",
    "    <tr><td>Classifier</td><td>F1</td></tr>\n",
    "    <tr><td>LogisticRegression</td><td>0.977</td></tr>\n",
    "    <tr><td>SVM</td><td>0.971</td></tr>\n",
    "    <tr><td>DecisionTreeClassifier</td><td>0.953</td></tr>\n",
    "    <tr><td>NaiveBayes</td><td>0.941</td></tr>\n",
    "    <tr><td>RandomForestClassifier</td><td>0.959</td></tr>\n",
    "    <tr><td>AdaBoostClassifier</td><td>0.971</td></tr>\n",
    "    <tr><td>VotingClassifier</td><td>0.971</td></tr>\n",
    "</table>\n",
    "\n",
    "### Wine\n",
    "\n",
    "<table>\n",
    "    <tr><td>Classifier</td><td>F1</td></tr>\n",
    "    <tr><td>LogisticRegression</td><td>1.000</td></tr>\n",
    "    <tr><td>SVM</td><td>0.982</td></tr>\n",
    "    <tr><td>DecisionTreeClassifier</td><td>0.963</td></tr>\n",
    "    <tr><td>NaiveBayes</td><td>1.000</td></tr>\n",
    "    <tr><td>RandomForestClassifier</td><td>0.982</td></tr>\n",
    "    <tr><td>AdaBoostClassifier</td><td>0.944</td></tr>\n",
    "    <tr><td>VotingClassifier</td><td>1.000</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
